---
title: "_pitmastr_: a standardized workflow for working with PIT tag data"
date:
output: 
  html_document:
    theme: flatly
    toc: yes
    number_sections: yes
    toc_float:
      collapsed: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Getting started with _pitmastr_

This document is a step-by-step guide to store and work with PIT tag data using 'pitmastr' package.

<div class = "alert alert-warning" role="alert">
Prior to using _pitmastr_, **users should have the following:**
</div>

<div style="color: black">
  - A <span style="background-color: #FFF9E4">common suffix/prefix appended to all folders</span> containing files downloaded from PIT tag reader. 
    - The main function of this package relies on a shared pattern string (i.e., suffix/prefix) to automate the search for files output from the readers. 
    - Accordingly, parent folders (those assigned a shared prefix) should only contain the files output from the reader, and **should not** contain subfolders or other xlsx, txt, or log files within them. (see section ## for example folder structure)
  - A <span style="background-color: #FFF9E4">map file, **m1**</span>, that contains connections between reader (often site names) based on serial number. Dates deployed at each site should be included if necessary (for example, if a reader was relocated to a different site).
  - A <span style="background-color: #FFF9E4">second map file, **m2**</span>, that contains biological variables users want to link to individuals (i.e, sex, species, etc). *Note*, these data should not be time-varying (age, mass).

</div>

# Load 'pitmastr' package

Step 1: Download all files from GitHub Repo: https://github.com/mkailing/pitmastr_demo

Step 2: Load (and install if necessary) 'devtools' package to be able to access bundled pitmastr package from local drive or git repo
```{r}
# if devtools is not already installed use: 
# install.packages("devtools")

# else, load to library
library(devtools)
```

Step 3: Install and load bundled 'pitmastr' from zip file
```{r}
## for now DO THIS:

#devtools::install_local("/Users/mkailing/Dropbox/Kailing_Projects/pitmastr_0.1.0.tar.gz") #this should path to zipped file with R package

# NOTE: may need to enter '1' in Console to update all package dependencies

#then, attach it to library
library(pitmastr)
```

# Data management

## File storage

The way detections on the reader are stored can vary depending on the model type and programmed settings. The folder structure we recommend accommodates most file types output by the readers *See below for caveat regarding .accdb. 

  - Data downloaded as .log files will store detections by date in a single file.
  - Newer systems allow for the export of several dates worth of detections into a single .txt or xlsx file. 
  
_pitmastr_ was created with this in mind and by storing as recommended, users can simultaneously assemble all detections from the various filetypes.

*_Users with detections stored as .accdb files are encouraged to export the table from MS Access as a .xlsx to be compatible with master file assembly through 'workhorse'_.

<center>

```{r echo=FALSE} 
knitr::include_graphics("/Users/mkailing/Dropbox/Kailing_Projects/scripts/3.pitmastr_methods/images/folderstructure.png")
```

</center>

![In the above example, there exists multiple readers at a single site that need to remain distinct. Each reader is assigned a name that joins the site and entrance.]

## Map file formats

R objects are highly sensitive to date and time formats. To streamline data manipulations, prior to assembling or manipulating data, format your map files to ensure compatibility with subsequent data assembly functions. The data should be in long format for ease of use. Below is an example of map file structure.

<center>

```{r echo=FALSE}
knitr::include_graphics(c("/Users/mkailing/Dropbox/Kailing_Projects/scripts/3.pitmastr_methods/images/m1_example.png","/Users/mkailing/Dropbox/Kailing_Projects/scripts/3.pitmastr_methods/images/m2_indmeta.png"))
```

</center>


### first, prepare your map1 file that contains reader information
'format_map1' requires 3 arguments:

  - **path.csv**, the file path where the map1 file that contains the dates, serial numbers, and locations (e.g., site names) of the readers
  - **date1**, column name of the deployment date of the readers at the site
  - **date2**, column name of the ending date for the reader at the site

This function will default to the current date for end date if the reader is still active at a site.

```{r}
# read in first map file (m1) and auto format with format_map1 function
m1 <- format_m1(path.csv = "/Users/mkailing/Dropbox/Kailing_Projects/pitmastr/inst/demo_dat/sn_map.csv",
                  date1 = start,
                  date2 = end)
#check dataframe
head(m1); tail(m1)
```

### second, prepare your map2 file that contains biological data associated with individuals
'format_map2' requires 3 arguments:

  - **path.csv**, the file path including the name of the map2 file that contains the biological data
  - **date1**, column name of the sampling dates (or start dates) of the readers at the respective site
  - **id.colname**, column name that contains pit tag IDs
  - **keep.cols**, combined list of columns that should be retained

```{r}
# read in second map file (m2) and auto format with format_map2 function
m2 <- format_m2(path.csv = "/Users/mkailing/Dropbox/Kailing_Projects/pitmastr/inst/demo_dat/bio_map.csv",
                           date1 = date,
                           id.colname = id,
                           keep.cols = c(sex, species, age, mass, site))

# check dataframe
head(m2); tail(m2)
```

# Data assembly
The first family of data functions within _pitmastr_ are used to wrangle data stored in PIT tag files. The primary data assembly function ('workhorse') will search the user specified directory (path) to find all files output by readers, extract the detections from those files and serial numbers of readers, and assemble them in a master dataframe that can be exported or manipulated subsequently. Objects returned from any of the assembly functions will have shared structure, so they can be combined easily using 'rbind' in base R.

## Assemble data...

### with **'workhorse'**
The 'workhorse' function was built to search all folders within the directory for each of the file types that can be exported by the readers.

'workhorse' requires three arguments: 

  - **path**, the directory containing folders that store files downloaded from readers
  - **string**, the shared prefix/suffix appended to all parent folders
  - **map.file1**, the name of an object created using 'format_map1'

and a fourth argument is optional:

  - **remove.dup**, specify whether duplicated detections should be dropped from master dataframe once assembled (i.e., if one row is an exact match to another). 
    - This argument defaults to "N", such that all rows will be retained even if exact matches exist. 
    - In most instances, duplicated rows are an artifact of accidentally duplicated data; 'remove.dup="Y"' is strongly suggested.

In our example dataset, the highest folders are the primary site names. Within them, the *_parent folders_* contain the prefix "LOGGER_", which is the pattern we call to the function indicating which folders to search for files containing detections from readers. The path up to the parent folder name will be included as a column in the returned object.

```{r}
pit <- workhorse(directory = "/Users/mkailing/Dropbox/Kailing_Projects/pitmastr/inst/demo_dat",
                string="LOGGER",
                map.file1 = m1)
# check dataframe
head(pit); tail(pit)
```

Or, try removing duplicates

```{r}
pit1 <- workhorse(directory = "/Users/mkailing/Dropbox/Kailing_Projects/pitmastr/inst/demo_dat",
                 string = "LOGGER_",
                 map.file1 = m1,
                 remove.dup = TRUE) #drops rows that have exact match with previous row (keeps single detection)
# check dataframe
head(pit1); tail(pit1)
```




### with **'extract'**
The 'extract_' functions may be beneficial for users that prefer to create a smaller object of detections from one reader/one file type. If desired, these objects can eventually be merged to one large dataframe using base R's 'rbind' function.

'extract' requires two arguments:

  - **path**, the folder containing files downloaded from reader
  - **filetype**, the extension for the type of file storing detections from the reader

```{r}
#df2 <- extract_txt(path = "/Users/mkailing/Dropbox/Kailing_Projects/pitmastr/test_MW/pitmastr_test", 
#               filetype = ".txt")
```


## Link individuals' metrics to PIT detections using 'integrate_ids'
The 'integrate_ids' function allows users to combine metadata on individuals to detections. 

'integrate_ids' requires three arguments:

  - **x**, the df containing detections (ie the object created with 'workhorse' or an object written with 'extract')
  - **y**, the map2 file, m2, containing individual metadata (i.e., species, sex, tag location, tag date) 
    _Note_: only time-independent variables may properly match. Time-varying factors that get included, such as mass, may not be properly reflected with detection dates
  - **joiner**, the name of the column containing PIT tag IDs that is shared between the master file and map file 2.

and a fourth argument is optional:
  - **remove.tt**, indicate whether test tags listed in the first map file (m1) should be removed (=FALSE, default) or retained
  (=TRUE)

  
The format of PIT tag IDS need to be consistent across objects. In our example, id and test.tag IDs contain the prefix "P_", but tags in pit_mastr do not.

```{r}
#remove prefix on PIT tag IDS
m2 %>% 
  mutate(id = gsub('P_', "", id)) -> m2
#in m1$test.tag as well
m1 %>% 
  mutate(test.tag = gsub('P_', "", test.tag)) -> m1

```

Dataframes can now be merged by the shared 'id' column.

```{r}
pit_working <- integrate_ids(pit, 
                             m2,
                             joiner = 'id')

## ------------- OR

pit_working <- integrate_ids(pit, 
                             m2,
                             joiner = 'id',
                             remove.tt = TRUE)  
head(pit_working); tail(pit_working)
```

# Data manipulation
This family of functions will create objects that users can use in simple statistical models and survival analyses.

'compress_id_date' function will return a dataframe with data summarized by PIT tag ID (or other grouping variables) and user-specific date time units. It requires XX arguments:

  - **x**, the df containing detections and desired grouping variables. In our example, we use the object returned from 'integrate_ids'
  - **obs.groups**, a list of column names by which the user wants data to be structured and summarized
  - **obs.units**, the time unit by which to summarize observations
  - **date.colname**, column name for date to summarize by
  
```{r}
ids_wks <- compress_ids_date(x = pit_working,
                             obs.groups =  c(id, sex, site.x),
                             obs.unit = "weeks",
                             date.colname = date)
head(ids_wks); tail(ids_wks)
```


```{r}
ids_months <- compress_ids_date(x = pit_working, 
                                obs.groups = c(id, sex, site.x),
                                obs.unit = "months", date.colname = date)
#head(ids_months); tail(ids_months)
```

'compress_id_surv' function return an object that can be used to perform survival analyses by way of the survival package (see 'survival'). It requires XX arguments:

  - **x**, name of the df containing all detections by date
  - **y**, name of the df containing all observation events (ie. PIT tag readers were operational) by date
  
- MACY WILL MANIPULATE mastr_pit TO INCLUDE ALL POSSIBLE SAMPLE EVENTS BASED ON READERS AND MAKE AN OBJECT COMPATIBLE WITH 'survival'

# Check status of readers

These functions are to evaluate the consistency (or identify gaps) in system operation and to create survival object (such that days when systems are running are considered a 'sample event').

'readr_check' will return a dataframe that counts the number of times a test tag was fired (metric for whether reader was working) by date for each system. It requires 3 arguments:

  - **x**, name of the object containing all detections (e.g., objects returned from the 'workhorse' function)
  - **y**, name of the map 1 file or (e.g. objects returned from format_map1) or vector that contains the list of test tag IDs
  - **site.col**, site (i.e., reader) column name in x. This allows user to evaluate coverage of each reader
  - **min.reads**, minimum number of test tag fires needed in a day for a system to be considered 'operating'. The value defaults to
  2.
  
```{r}
# system_ops <- readr_check(x = mastr_pit, #if file is not stored in working directory, full file path will be required
#                            y = m1,
#                            min.reads = 3) 
```
  
'readr_viz' will summarize test tag detections by user-defined time frame and plot output as ggplot object. It requires 2 arguments:

  - **df**, name of the dataframe that summarizes test tags fired (e.g., the object returned using readr_check)
  - **site.col**, column name that distinguishes readers

- MACY WILL MAKE THIS PLOT MORE APPEALING!!

```{r}
# plot_system_ops <- readr_viz(df = system_ops,
#                               site.col = path)
```

# Explore data using Shiny plots


